import os
import json
import requests
from duckduckgo_search import DDGS  # ç”¨äºçœŸå®æœç´¢
from openai import OpenAI  # ç”¨äºè°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ€»ç»“

# --- 1. é…ç½®åŒºåŸŸ (ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå®‰å…¨ç¬¬ä¸€) ---
DINGTALK_WEBHOOK = os.getenv("DINGTALK_WEBHOOK")
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.openai.com/v1") # å¦‚æœç”¨åˆ«çš„æ¨¡å‹(å¦‚DeepSeek/Gemini)ï¼Œæ”¹è¿™é‡Œ
LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME", "gpt-4o") # æŒ‡å®šæ¨¡å‹

# å®šä¹‰æˆ‘ä»¬è¦å…³æ³¨çš„å…³é”®è¯
SEARCH_KEYWORDS = [
    "Nu Mexico new features app design 2025",
    "Stori Mexico credit card update",
    "RappiCard Mexico changes",
    "ComisiÃ³n Nacional Bancaria y de Valores Mexico regulation fintech"
]

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šæœç´¢ ---
def search_web():
    print("ğŸ” æ­£åœ¨å…¨ç½‘æœç´¢æœ€æ–°æƒ…æŠ¥...")
    results = []
    # ä½¿ç”¨ DuckDuckGo å…è´¹æœç´¢
    with DDGS() as ddgs:
        for keyword in SEARCH_KEYWORDS:
            try:
                # æ¯ä¸ªå…³é”®è¯æŠ“å–å‰ 3 æ¡æœ€æ–°ç»“æœ
                print(f"  - æœç´¢: {keyword}")
                keywords_results = list(ddgs.text(keyword, max_results=3))
                for r in keywords_results:
                    results.append(f"æ ‡é¢˜: {r['title']}\né“¾æ¥: {r['href']}\næ‘˜è¦: {r['body']}")
            except Exception as e:
                print(f"  âŒ æœç´¢ '{keyword}' æ—¶å‡ºé”™: {e}")
    
    return "\n---\n".join(results)

# --- 3. æ ¸å¿ƒåŠŸèƒ½ï¼šAI åˆ†æ (å¤§è„‘) ---
def analyze_content(raw_data):
    if not raw_data:
        return "âš ï¸ ä»Šæ—¥æœªæœç´¢åˆ°æœ‰æ•ˆä¿¡æ¯ï¼Œè¯·æ£€æŸ¥æœç´¢æºã€‚"

    print("ğŸ§  æ­£åœ¨è°ƒç”¨ AI è¿›è¡Œæ·±åº¦åˆ†æ...")
    
    client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)

    # ä¸“é—¨ä¸º PM è®¾è®¡çš„ Prompt
    prompt = f"""
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Fintechäº§å“ç»ç†ï¼Œä¸“æ³¨äºå¢¨è¥¿å“¥å¸‚åœºã€‚
    è¯·é˜…è¯»ä»¥ä¸‹ä»ç½‘ç»œæŠ“å–çš„æœç´¢ç»“æœï¼ˆå¯èƒ½åŒ…å«å™ªéŸ³ï¼‰ï¼Œä¸ºæˆ‘æ’°å†™ä¸€ä»½ã€å¢¨è¥¿å“¥ç«å“æ¯æ—¥æƒ…æŠ¥ã€‘ã€‚

    æœç´¢ç»“æœæ•°æ®ï¼š
    {raw_data}

    æ’°å†™è¦æ±‚ï¼š
    1. **è¯­è¨€**ï¼šä½¿ç”¨ä¸­æ–‡ã€‚
    2. **æ ¼å¼**ï¼šMarkdownã€‚
    3. **æ ¸å¿ƒå…³æ³¨ç‚¹**ï¼š
       - **ç«å“åŠ¨å‘**ï¼šNu, Stori, Rappi ç­‰æ˜¯å¦æœ‰æ–°åŠŸèƒ½ã€æ–°UIè®¾è®¡ã€æ–°äº¤äº’æµç¨‹ï¼Ÿ(é‡ç‚¹æå–å…·ä½“çš„è®¾è®¡ç»†èŠ‚)
       - **åˆè§„é£å‘**ï¼šCNBV æˆ–å¢¨è¥¿å“¥æ”¿åºœæ˜¯å¦æœ‰æ–°è§„å®šï¼Ÿ
    4. **å»å™ª**ï¼šå¿½ç•¥æ— å…³å¹¿å‘Šã€æ—§é—»ï¼ˆè¶…è¿‡1å¹´çš„ï¼‰å’Œæ²¡æœ‰å®è´¨å†…å®¹çš„è½¯æ–‡ã€‚
    5. **è¯­æ°”**ï¼šä¸“ä¸šã€ç®€ç»ƒã€ç›´æ¥ã€‚
    6. **ç»“å°¾**ï¼šå¿…é¡»åˆ—å‡º1-2ä¸ªæœ€æœ‰ä»·å€¼çš„åŸæ–‡æ¥æºé“¾æ¥ã€‚

    è¯·ç›´æ¥è¾“å‡ºæŠ¥å‘Šå†…å®¹ã€‚
    """

    try:
        response = client.chat.completions.create(
            model=LLM_MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ AI åˆ†æå¤±è´¥: {e}"

# --- 4. æ ¸å¿ƒåŠŸèƒ½ï¼šå‘é€é’‰é’‰ ---
def send_dingtalk(content):
    print("ğŸš€ æ­£åœ¨å‘é€åˆ°é’‰é’‰ç¾¤...")
    headers = {'Content-Type': 'application/json'}
    data = {
        "msgtype": "markdown",
        "markdown": {
            "title": "ğŸ‡²ğŸ‡½ å¢¨è¥¿å“¥Fintechæ—¥æŠ¥",
            "text": f"### ğŸ‡²ğŸ‡½ å¢¨è¥¿å“¥Fintechå¸‚åœºæ—¥æŠ¥\n\n{content}"
        }
    }
    requests.post(DINGTALK_WEBHOOK, headers=headers, data=json.dumps(data))

# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    # 1. è·å–åŸå§‹ä¿¡æ¯
    raw_search_data = search_web()
    
    # 2. AI æç‚¼
    final_report = analyze_content(raw_search_data)
    
    # 3. æ¨é€
    send_dingtalk(final_report)
    print("âœ… ä»»åŠ¡å®Œæˆï¼")
